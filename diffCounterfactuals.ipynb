{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: /home/dai/GPU-Student-2/Cederic/DataSciPro/data_output_test/folder_IMG_27300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'timestep_values': None, 'timesteps': 1000} were passed to DDIMScheduler, but are not expected and will be ignored. Please verify your scheduler_config.json configuration file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.2704, device='cuda:0')\n",
      "tensor([False])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/home/dai/GPU-Student-2/Cederic/anaconda3/envs/diffcounter/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "100%|██████████| 99/99 [00:02<00:00, 39.86it/s]\n",
      "/home/dai/GPU-Student-2/Cederic/anaconda3/envs/diffcounter/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier prediction: -1.37044358253479\n",
      "0 loss: 2.778909921646118 lr: [0.01] l1-dist 0.040846627205610275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dai/GPU-Student-2/Cederic/anaconda3/envs/diffcounter/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:855: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "  0%|          | 0/1 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 341\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (current_pred \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m&\u001b[39m (i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m20\u001b[39m) :\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m#for i in tqdm(range(num_optimization_steps)):\u001b[39;00m\n\u001b[1;32m    340\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 341\u001b[0m         x, x0 \u001b[38;5;241m=\u001b[39m \u001b[43mdiffusion_pipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_inference_steps\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# forward\u001b[39;00m\n\u001b[1;32m    342\u001b[0m         decoded_x \u001b[38;5;241m=\u001b[39m vqvae\u001b[38;5;241m.\u001b[39mdecode(x)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    343\u001b[0m         current_pred \u001b[38;5;241m=\u001b[39m classifier(decoded_x)[\u001b[38;5;241m0\u001b[39m][cls_id]\n",
      "Cell \u001b[0;32mIn[18], line 267\u001b[0m, in \u001b[0;36mdiffusion_pipe\u001b[0;34m(noise_module, num_inference_steps)\u001b[0m\n\u001b[1;32m    265\u001b[0m z \u001b[38;5;241m=\u001b[39m scheduler\u001b[38;5;241m.\u001b[39mscale_model_input(z, t)\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 267\u001b[0m     noise_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheckpointed_unet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    268\u001b[0m z \u001b[38;5;241m=\u001b[39m scheduler\u001b[38;5;241m.\u001b[39mstep(noise_pred, t, z)\u001b[38;5;241m.\u001b[39mprev_sample\n\u001b[1;32m    269\u001b[0m z0 \u001b[38;5;241m=\u001b[39m scheduler\u001b[38;5;241m.\u001b[39mstep(noise_pred, t, z)\u001b[38;5;241m.\u001b[39mpred_original_sample\n",
      "File \u001b[0;32m~/Cederic/anaconda3/envs/diffcounter/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Cederic/anaconda3/envs/diffcounter/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 77\u001b[0m, in \u001b[0;36mCheckpointedUNetWrapper.forward\u001b[0;34m(self, sample, timestep)\u001b[0m\n\u001b[1;32m     75\u001b[0m         sample, skip_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpointed_forward(upsample_block, sample, res_samples, emb, skip_sample)\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m         sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpointed_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupsample_block\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# 6. post-process\u001b[39;00m\n\u001b[1;32m     80\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconv_norm_out(sample)\n",
      "Cell \u001b[0;32mIn[18], line 33\u001b[0m, in \u001b[0;36mCheckpointedUNetWrapper.checkpointed_forward\u001b[0;34m(self, module, *inputs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom_forward\u001b[39m(\u001b[38;5;241m*\u001b[39minputs):\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m module(\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustom_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Cederic/anaconda3/envs/diffcounter/lib/python3.10/site-packages/torch/_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Cederic/anaconda3/envs/diffcounter/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:451\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m prior \u001b[38;5;241m=\u001b[39m set_eval_frame(callback)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m~/Cederic/anaconda3/envs/diffcounter/lib/python3.10/site-packages/torch/_dynamo/external_utils.py:36\u001b[0m, in \u001b[0;36mwrap_inline.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Cederic/anaconda3/envs/diffcounter/lib/python3.10/site-packages/torch/utils/checkpoint.py:487\u001b[0m, in \u001b[0;36mcheckpoint\u001b[0;34m(function, use_reentrant, context_fn, determinism_check, debug, *args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m context_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m noop_context_fn \u001b[38;5;129;01mor\u001b[39;00m debug \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing `context_fn` or `debug` is only supported when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_reentrant=False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    486\u001b[0m         )\n\u001b[0;32m--> 487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCheckpointFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m     gen \u001b[38;5;241m=\u001b[39m _checkpoint_without_reentrant_generator(\n\u001b[1;32m    490\u001b[0m         function, preserve, context_fn, determinism_check, debug, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    491\u001b[0m     )\n",
      "File \u001b[0;32m~/Cederic/anaconda3/envs/diffcounter/lib/python3.10/site-packages/torch/autograd/function.py:598\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    597\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    602\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    603\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    604\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    605\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    606\u001b[0m     )\n",
      "File \u001b[0;32m~/Cederic/anaconda3/envs/diffcounter/lib/python3.10/site-packages/torch/utils/checkpoint.py:262\u001b[0m, in \u001b[0;36mCheckpointFunction.forward\u001b[0;34m(ctx, run_function, preserve_rng_state, *args)\u001b[0m\n\u001b[1;32m    259\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(\u001b[38;5;241m*\u001b[39mtensor_inputs)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 262\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mrun_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "Cell \u001b[0;32mIn[18], line 32\u001b[0m, in \u001b[0;36mCheckpointedUNetWrapper.checkpointed_forward.<locals>.custom_forward\u001b[0;34m(*inputs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom_forward\u001b[39m(\u001b[38;5;241m*\u001b[39minputs):\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Cederic/anaconda3/envs/diffcounter/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Cederic/anaconda3/envs/diffcounter/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Cederic/anaconda3/envs/diffcounter/lib/python3.10/site-packages/diffusers/models/unets/unet_2d_blocks.py:2664\u001b[0m, in \u001b[0;36mUpBlock2D.forward\u001b[0;34m(self, hidden_states, res_hidden_states_tuple, temb, upsample_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2660\u001b[0m             hidden_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m   2661\u001b[0m                 create_custom_forward(resnet), hidden_states, temb\n\u001b[1;32m   2662\u001b[0m             )\n\u001b[1;32m   2663\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2664\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mresnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsamplers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2667\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m upsampler \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsamplers:\n",
      "File \u001b[0;32m~/Cederic/anaconda3/envs/diffcounter/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Cederic/anaconda3/envs/diffcounter/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Cederic/anaconda3/envs/diffcounter/lib/python3.10/site-packages/diffusers/models/resnet.py:346\u001b[0m, in \u001b[0;36mResnetBlock2D.forward\u001b[0;34m(self, input_tensor, temb, *args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m     input_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample(input_tensor)\n\u001b[1;32m    344\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample(hidden_states)\n\u001b[0;32m--> 346\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_emb_proj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_time_act:\n",
      "File \u001b[0;32m~/Cederic/anaconda3/envs/diffcounter/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Cederic/anaconda3/envs/diffcounter/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Cederic/anaconda3/envs/diffcounter/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Cederic/anaconda3/envs/diffcounter/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import PIL.Image\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import imageio\n",
    "import math\n",
    "import os\n",
    "\n",
    "from diffusers import UNet2DModel, DDIMScheduler, VQModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from zennit.composites import LayerMapComposite\n",
    "from zennit.rules import Epsilon, ZPlus, Pass, Norm\n",
    "\n",
    "from data.dataset import ImageDataset, CelebHQAttrDataset\n",
    "from init_classifier import LinearClassifier, VQVAEClassifier, ResNet50Classifier\n",
    "from xai_lrp import xai_zennit, show_attributions\n",
    "\n",
    "\n",
    "class CheckpointedUNetWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(CheckpointedUNetWrapper, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def checkpointed_forward(self, module, *inputs):\n",
    "        def custom_forward(*inputs):\n",
    "            return module(*inputs)\n",
    "        return checkpoint(custom_forward, *inputs)\n",
    "\n",
    "    def forward(self, sample, timestep):\n",
    "\n",
    "        # 1. time\n",
    "        timesteps = timestep\n",
    "        if not torch.is_tensor(timesteps):\n",
    "            timesteps = torch.tensor([timesteps], dtype=torch.long, device=sample.device)\n",
    "        elif torch.is_tensor(timesteps) and len(timesteps.shape) == 0:\n",
    "            timesteps = timesteps[None].to(sample.device)\n",
    "\n",
    "        # broadcast to batch dimension in a way that's compatible with ONNX/Core ML\n",
    "        timesteps = timesteps * torch.ones(sample.shape[0], dtype=timesteps.dtype, device=timesteps.device)\n",
    "\n",
    "        t_emb = self.model.time_proj(timesteps)\n",
    "        #t_emb = t_emb.to(dtype=self.dtype)\n",
    "        emb = self.model.time_embedding(t_emb)\n",
    "\n",
    "        # 2. pre-process\n",
    "        skip_sample = sample\n",
    "        sample = self.model.conv_in(sample)\n",
    "\n",
    "        # 3. down\n",
    "        down_block_res_samples = (sample,)\n",
    "        for downsample_block in self.model.down_blocks:\n",
    "            if hasattr(downsample_block, \"skip_conv\"):\n",
    "                sample, res_samples, skip_sample = self.checkpointed_forward(downsample_block, sample, emb, skip_sample)\n",
    "            else:\n",
    "                sample, res_samples = self.checkpointed_forward(downsample_block, sample, emb)\n",
    "\n",
    "            down_block_res_samples += res_samples\n",
    "        \n",
    "        # 4. mid\n",
    "        sample = self.checkpointed_forward(self.model.mid_block, sample, emb)\n",
    "\n",
    "        # 5. up\n",
    "        skip_sample = None\n",
    "        for upsample_block in self.model.up_blocks:\n",
    "            res_samples = down_block_res_samples[-len(upsample_block.resnets) :]\n",
    "            down_block_res_samples = down_block_res_samples[: -len(upsample_block.resnets)]\n",
    "\n",
    "            if hasattr(upsample_block, \"skip_conv\"):\n",
    "                sample, skip_sample = self.checkpointed_forward(upsample_block, sample, res_samples, emb, skip_sample)\n",
    "            else:\n",
    "                sample = self.checkpointed_forward(upsample_block, sample, res_samples, emb)\n",
    "\n",
    "        # 6. post-process\n",
    "        sample = self.model.conv_norm_out(sample)\n",
    "        sample = self.model.conv_act(sample)\n",
    "        sample = self.model.conv_out(sample)\n",
    "\n",
    "        if skip_sample is not None:\n",
    "            sample += skip_sample\n",
    "\n",
    "        return {\"sample\": sample}\n",
    "\n",
    "def classifier_loss(classifier, images, targets, idx):\n",
    "    preds = classifier(images)\n",
    "    if idx % 2 == 0:\n",
    "        print(f\"Classifier prediction: {preds[0][cls_id]}\")\n",
    "    targets = torch.tensor(targets).to(device)\n",
    "    #error = torch.nn.functional.binary_cross_entropy_with_logits(preds[0][31], targets)\n",
    "    error = torch.abs(preds[0][cls_id] - targets).mean()\n",
    "    preds_binary = torch.sigmoid(preds[0][cls_id]) > 0.5    \n",
    "\n",
    "    return error, preds_binary\n",
    "\n",
    "def minDist_loss(images, original_images):\n",
    "    error = torch.abs(images - original_images).mean()\n",
    "    return error\n",
    "\n",
    "\n",
    "# data loading with ground truth no smiling\n",
    "data = ImageDataset('/home/dai/GPU-Student-2/Cederic/DataSciPro/data/misclsData_gt0', image_size=256, exts=['jpg', 'JPG', 'png'], do_augment=False, sort_names=True)\n",
    "dataloader = DataLoader(data, batch_size=1, shuffle=False)\n",
    "\n",
    "# create output folders\n",
    "directory_names = []\n",
    "for i, _ in enumerate(dataloader):\n",
    "    img_index = dataloader.dataset.paths[i].name.split('_')[0]\n",
    "    directory_name = os.path.join(\"/home/dai/GPU-Student-2/Cederic/DataSciPro/data_output_test\", f'folder_IMG_{img_index}')\n",
    "    directory_names.append(directory_name)\n",
    "    os.makedirs(directory_name, exist_ok=True)\n",
    "    print(f'Created directory: {directory_name}')\n",
    "\n",
    "#\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cls_type = 'linear'\n",
    "cls_id =  CelebHQAttrDataset.cls_to_id['Smiling']\n",
    "\n",
    "# load all models\n",
    "unet = UNet2DModel.from_pretrained(\"CompVis/ldm-celebahq-256\", subfolder=\"unet\")\n",
    "vqvae = VQModel.from_pretrained(\"CompVis/ldm-celebahq-256\", subfolder=\"vqvae\")\n",
    "scheduler = DDIMScheduler.from_config(\"CompVis/ldm-celebahq-256\", subfolder=\"scheduler\")\n",
    "\n",
    "unet.to(device)\n",
    "vqvae.to(device)\n",
    "\n",
    "checkpointed_unet = CheckpointedUNetWrapper(unet)\n",
    "\n",
    "# load all models\n",
    "if cls_type == 'linear':    \n",
    "    classifier = LinearClassifier.load_from_checkpoint(\"/home/dai/GPU-Student-2/Cederic/DataSciPro/cls_checkpoints/ffhq256.b128linear2024-06-02 13:08:28.ckpt\",\n",
    "                                            input_dim = data[0]['img'].shape,\n",
    "                                            num_classes = len(CelebHQAttrDataset.id_to_cls))\n",
    "elif cls_type == 'vqvae':\n",
    "    classifier = VQVAEClassifier.load_from_checkpoint(\"/home/dai/GPU-Student-2/Cederic/DataSciPro/cls_checkpoints/ffhq256.b32vqvae2024-06-01 08:48:59.ckpt\",\n",
    "                                           num_classes = len(CelebHQAttrDataset.id_to_cls))\n",
    "    \n",
    "elif cls_type == 'res50':\n",
    "    classifier = ResNet50Classifier.load_from_checkpoint(\"/home/dai/GPU-Student-2/Cederic/DataSciPro/cls_checkpoints/ffhq256.b64res502024-06-02 17:06:41.ckpt\",\n",
    "                                            num_classes = len(CelebHQAttrDataset.id_to_cls))\n",
    "\n",
    "classifier.to(device)\n",
    "classifier.eval()\n",
    "# check functionality of classifier\n",
    "all_outputs = []\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        inputs = batch['img'].to(classifier.device)\n",
    "        outputs = classifier(inputs)\n",
    "        print(outputs[0][cls_id])\n",
    "\n",
    "        preds_binary = torch.sigmoid(outputs[:, cls_id].cpu()) > 0.5\n",
    "        all_outputs.append(preds_binary) \n",
    "all_outputs = torch.cat(all_outputs, dim=0)\n",
    "print(all_outputs)\n",
    "\n",
    "\n",
    "###### explainable ai lrp\n",
    "# lrp rules\n",
    "layer_map_lrp_0 = [\n",
    "    (torch.nn.ReLU, Pass()),  # ignore activations\n",
    "    (torch.nn.Linear, Epsilon(epsilon=0)),  # this is the dense Linear, not any Linear\n",
    "    (torch.nn.Conv2d, ZPlus()),\n",
    "    (torch.nn.BatchNorm2d, Pass()),\n",
    "    (torch.nn.AdaptiveAvgPool2d, Norm()),\n",
    "]\n",
    "\n",
    "layer_map_lrp_zplus = [\n",
    "    (torch.nn.ReLU, Pass()),\n",
    "    (torch.nn.Linear, ZPlus()),  # this is the dense Linear, not any Linear\n",
    "    (torch.nn.Conv2d, ZPlus()),\n",
    "    (torch.nn.BatchNorm2d, Pass()),\n",
    "    (torch.nn.AdaptiveAvgPool2d, Norm()),\n",
    "]\n",
    "\n",
    "layer_map_lrp_eps = [\n",
    "    (torch.nn.ReLU, Pass()),\n",
    "    (torch.nn.Linear, Epsilon(epsilon=1)),  # this is the dense Linear, not any Linear\n",
    "    (torch.nn.Conv2d, ZPlus()),\n",
    "    (torch.nn.BatchNorm2d, Pass()),\n",
    "    (torch.nn.AdaptiveAvgPool2d, Norm()),\n",
    "]\n",
    "\n",
    "#before manipulation\n",
    "for i, batch in enumerate(dataloader):\n",
    "    inputs = batch['img'].to(classifier.device)\n",
    "    attr_znt_0 = [xai_zennit(classifier, inputs, RuleComposite=LayerMapComposite(layer_map_lrp_0), device=device, target=torch.tensor(cls_id).to(device))[0]]\n",
    "    attr_znt_eps = [xai_zennit(classifier, inputs, RuleComposite=LayerMapComposite(layer_map_lrp_eps), device=device, target=torch.tensor(cls_id).to(device))[0]]\n",
    "    attr_znt_zplus = [xai_zennit(classifier, inputs, RuleComposite=LayerMapComposite(layer_map_lrp_zplus), device=device, target=torch.tensor(cls_id).to(device))[0]]\n",
    "    show_attributions(directory_names[i], attr_znt_0, title='Pre Zennit LRP-0')\n",
    "    show_attributions(directory_names[i], attr_znt_eps, title='Pre Zennit LRP-EPS')\n",
    "    show_attributions(directory_names[i], attr_znt_zplus, title='Pre Zennit LRP-Z+')\n",
    "        \n",
    "## Inversion\n",
    "def invert(\n",
    "    start_latents,\n",
    "    num_inference_steps,\n",
    "    device=device,\n",
    "):\n",
    "\n",
    "    # Latents are now the specified start latents\n",
    "    latents = start_latents.clone()\n",
    "\n",
    "    # We'll keep a list of the inverted latents as the process goes on\n",
    "    intermediate_latents = []\n",
    "\n",
    "    # Set num inference steps\n",
    "    scheduler.set_timesteps(num_inference_steps, device=device)\n",
    "\n",
    "    # Reversed timesteps <<<<<<<<<<<<<<<<<<<<\n",
    "    timesteps = reversed(scheduler.timesteps)\n",
    "\n",
    "    for i in tqdm(range(1, num_inference_steps), total=num_inference_steps - 1):\n",
    "\n",
    "        # We'll skip the final iteration\n",
    "        if i >= num_inference_steps - 1:\n",
    "            continue\n",
    "\n",
    "        t = timesteps[i]\n",
    "\n",
    "        # Expand the latents if we are doing classifier free guidance\n",
    "        latent_model_input = latents\n",
    "        latent_model_input = scheduler.scale_model_input(latent_model_input, t)\n",
    "\n",
    "        # Predict the noise residual\n",
    "        noise_pred = checkpointed_unet(latent_model_input, t)[\"sample\"]\n",
    "\n",
    "        current_t = max(0, t.item() - (1000 // num_inference_steps))  # t\n",
    "        next_t = t  # min(999, t.item() + (1000//num_inference_steps)) # t+1\n",
    "        alpha_t = scheduler.alphas_cumprod[current_t]\n",
    "        alpha_t_next = scheduler.alphas_cumprod[next_t]\n",
    "\n",
    "        # Inverted update step (re-arranging the update step to get x(t) (new latents) as a function of x(t-1) (current latents)\n",
    "        latents = (latents - (1 - alpha_t).sqrt() * noise_pred) * (alpha_t_next.sqrt() / alpha_t.sqrt()) + (\n",
    "            1 - alpha_t_next\n",
    "        ).sqrt() * noise_pred\n",
    "\n",
    "        # Store\n",
    "        intermediate_latents.append(latents)\n",
    "\n",
    "    return torch.cat(intermediate_latents)\n",
    "\n",
    "\n",
    "class LatentNoise(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    The LatentNoise Module makes it easier to update the noise tensor with torch optimizers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, noise: torch.Tensor):\n",
    "        super().__init__()\n",
    "        self.noise = torch.nn.Parameter(noise)\n",
    "\n",
    "    def forward(self):\n",
    "        return self.noise\n",
    "\n",
    "\n",
    "def diffusion_pipe(noise_module: LatentNoise, num_inference_steps):\n",
    "        z = noise_module()\n",
    "        for i in range(start_step, num_inference_steps):\n",
    "            t = scheduler.timesteps[i]\n",
    "            z = scheduler.scale_model_input(z, t)\n",
    "            with torch.no_grad():\n",
    "                noise_pred = checkpointed_unet(z, t)[\"sample\"]\n",
    "            z = scheduler.step(noise_pred, t, z).prev_sample\n",
    "            z0 = scheduler.step(noise_pred, t, z).pred_original_sample\n",
    "        return z, z0\n",
    "\n",
    "def plot_images(images, titles=None, figsize=(50, 5), save_path=None):\n",
    "    n = len(images)\n",
    "    fig, axes = plt.subplots(1, n, figsize=figsize)\n",
    "\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "        if titles is not None:\n",
    "            axes[i].set_title(titles[i])\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    #plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "def plot_to_pil(tensor):\n",
    "    image = tensor.cpu().permute(0, 2, 3, 1).clip(-1,1) * 0.5 + 0.5\n",
    "    image = PIL.Image.fromarray(np.array(image[0].detach().numpy() * 255).astype(np.uint8))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def tensor_to_pil_image(tensor):\n",
    "    image = tensor.cpu().permute(0, 2, 3, 1).clip(-1,1) * 0.5 + 0.5\n",
    "    image = PIL.Image.fromarray(np.array(image[0].detach().numpy() * 255).astype(np.uint8))\n",
    "    return image\n",
    "\n",
    "# conditional sampling\n",
    "num_inference_steps = 100\n",
    "start_step = 20\n",
    "\n",
    "\n",
    "for step, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "    #plot_to_pil(batch['img'])\n",
    "    with torch.no_grad():\n",
    "        z = vqvae.encode(batch['img'].to(device))   # encode the image in the latent space\n",
    "    z = z.latents\n",
    "    \n",
    "    #cond = z.view(1,-1)\n",
    "    #cond = normalize(cond)\n",
    "    #cond = cond + 0.5 * math.sqrt(512) * classifier.fc1.weight[31].unsqueeze(0)\n",
    "    #cond = denormalize(cond)\n",
    "    #z = cond.view(1,3,64,64)\n",
    "    #dec_z = vqvae.decode(z)[0]\n",
    "    #plot_to_pil(dec_z)\n",
    "    \n",
    "    inverted_latents = invert(z, num_inference_steps)                  # do the ddim scheduler reversed to add noise to the latents\n",
    "    z = inverted_latents[-(start_step + 1)].unsqueeze(0)                  # use these latents to start the sampling. better performance when using not the last latent sample\n",
    "    noise_module = LatentNoise(z.clone()).to(device)                    # convert latent noise to a parameter module for optimization\n",
    "    noise_module.noise.requires_grad = True\n",
    "    intermediate_results = [batch['img'].to(device)]   # list to store the results of the steering\n",
    "    intermediate_preds = [round(classifier(batch['img'].to(device))[0][cls_id].item(), 5)]\n",
    "    \n",
    "    optimizer = torch.optim.Adam(\n",
    "        noise_module.parameters(), lr=0.01, maximize=False # not minimize gradient ascent\n",
    "    )\n",
    "    learning_scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "    \n",
    "    x = torch.zeros_like(z)\n",
    "    current_loss = float('inf')\n",
    "    preds_binary = False\n",
    "    current_pred = 0.0\n",
    "    i = 0\n",
    "    while (current_pred < 1.0) & (i < 20) :\n",
    "    #for i in tqdm(range(num_optimization_steps)):\n",
    "            optimizer.zero_grad()\n",
    "            x, x0 = diffusion_pipe(noise_module, num_inference_steps) # forward\n",
    "            decoded_x = vqvae.decode(x)[0]\n",
    "            current_pred = classifier(decoded_x)[0][cls_id]\n",
    "\n",
    "            if i % 1 == 0:\n",
    "                intermediate_results.append(decoded_x)\n",
    "                intermediate_preds.append(round(current_pred.item(), 5))\n",
    "\n",
    "            loss, preds_binary = classifier_loss(classifier, decoded_x, 1.0, i)\n",
    "            l1_dist = minDist_loss(decoded_x, batch['img'].to(device))\n",
    "            loss += l1_dist * 10\n",
    "            \n",
    "            if i % 2 == 0:\n",
    "                print(i, \"loss:\", loss.item(), \"lr:\", learning_scheduler.get_lr(), \"l1-dist\", l1_dist.item())\n",
    "                #print(i, \"loss:\", loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            learning_scheduler.step()\n",
    "\n",
    "            current_loss = loss.item()\n",
    "            i += 1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image = vqvae.decode(x)[0]\n",
    "\n",
    "    print(f\"Diffusion Counterfactual generated with loss: {current_loss} | classifier_prediction: {current_pred} | l1_dist: {l1_dist} | in {i} optimization steps\")\n",
    "    \n",
    "    #lrp after manipulation\n",
    "    attr_znt_0 = [xai_zennit(classifier, image, RuleComposite=LayerMapComposite(layer_map_lrp_0), device=device, target=torch.tensor(cls_id).to(device))[0]]\n",
    "    attr_znt_eps = [xai_zennit(classifier, image, RuleComposite=LayerMapComposite(layer_map_lrp_eps), device=device, target=torch.tensor(cls_id).to(device))[0]]\n",
    "    attr_znt_zplus = [xai_zennit(classifier, image, RuleComposite=LayerMapComposite(layer_map_lrp_zplus), device=device, target=torch.tensor(cls_id).to(device))[0]]\n",
    "    show_attributions(directory_names[step], attr_znt_0, title='Post Zennit LRP-0')\n",
    "    show_attributions(directory_names[step], attr_znt_eps, title='Post Zennit LRP-EPS')\n",
    "    show_attributions(directory_names[step], attr_znt_zplus, title='Post Zennit LRP-Z+')\n",
    "    image.requires_grad = False\n",
    "    \n",
    "    images = [tensor_to_pil_image(tensor) for tensor in intermediate_results]\n",
    "    gif_path = f\"{directory_names[step]}/GIF.gif\"\n",
    "    imageio.mimsave(gif_path, images, format='GIF', duration=2.0, loop=0)  # duration is in seconds\n",
    "\n",
    "    row_path = f\"{directory_names[step]}/sequence.png\"\n",
    "    plot_images(images, intermediate_preds, save_path=row_path)\n",
    "\n",
    "    # process image\n",
    "    image_processed = image.cpu().permute(0, 2, 3, 1).clip(-1,1) * 0.5 + 0.5\n",
    "    image_pil = PIL.Image.fromarray(np.array(image_processed[0] * 255).astype(np.uint8))\n",
    "    ori_processed = batch['img'].cpu().permute(0, 2, 3, 1).clip(-1,1) * 0.5 + 0.5\n",
    "    ori_image = PIL.Image.fromarray(np.array(ori_processed[0] * 255).astype(np.uint8))\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(image_pil)\n",
    "    axs[0].axis('off')\n",
    "    axs[0].set_title('Diffusion Counterfactual Image')\n",
    "    axs[1].imshow(ori_image)\n",
    "    axs[1].axis('off')\n",
    "    axs[1].set_title('Original Image')\n",
    "    #plt.show()\n",
    "    fig.savefig(f'{directory_names[step]}/ori_vs_DCE.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    image_pil.save(f\"{directory_names[step]}/diffCounter_IMG.png\")\n",
    "    print('finish')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffcounter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
